# Synaptic Assistant — Model Roster & Voice Configuration
#
# This file is the single source of truth for available LLM models and voice settings.
# It is loaded at boot by Assistant.Config.Loader and hot-reloaded on file change.
#
# Env var interpolation: Use ${ENV_VAR} for sensitive values (resolved at load time).
# Unresolved env vars raise at boot; missing optional vars resolve to null.

# ---------------------------------------------------------------------------
# Defaults — which model tier to use for each system role
# ---------------------------------------------------------------------------
defaults:
  orchestrator: primary
  sub_agent: balanced
  compaction: fast
  sentinel: fast
  audio_transcription: fast     # STT — model that can process audio input
  audio_output: primary         # TTS via model (e.g. gpt-audio) — alternative/complement to ElevenLabs

# ---------------------------------------------------------------------------
# Model Roster — curated list of OpenRouter models
# ---------------------------------------------------------------------------
#
# Fields:
#   id              OpenRouter model identifier (provider/model-name)
#   tier            primary | balanced | fast | cheap
#   description     Human-readable summary
#   use_cases       List of roles this model is suitable for:
#                     orchestrator, sub_agent, compaction, sentinel,
#                     audio_transcription (can process audio/speech input — STT),
#                     audio_output (can generate audio/speech output — TTS via model)
#   supports_tools  Whether the model supports tool/function calling
#   max_context_tokens  Maximum context window size
#   cost_tier       low | medium | high (relative cost classification)

models:
  - id: "anthropic/claude-sonnet-4-6"
    tier: primary
    description: "Claude Sonnet 4.6 — top-tier reasoning, tool calling, and instruction following"
    use_cases:
      - orchestrator
      - sub_agent
    supports_tools: true
    max_context_tokens: 200000
    cost_tier: high

  - id: "anthropic/claude-sonnet-4-20250514"
    tier: primary
    description: "Claude Sonnet 4 — strong reasoning and tool calling, previous generation"
    use_cases:
      - orchestrator
      - sub_agent
    supports_tools: true
    max_context_tokens: 200000
    cost_tier: high

  - id: "google/gemini-2.5-flash-preview-05-20"
    tier: balanced
    description: "Gemini 2.5 Flash — fast, capable, large context, good tool use"
    use_cases:
      - orchestrator
      - sub_agent
      - compaction
    supports_tools: true
    max_context_tokens: 1048576
    cost_tier: medium

  - id: "anthropic/claude-haiku-4-5-20251001"
    tier: fast
    description: "Claude Haiku 4.5 — fast and cheap, good for lightweight tasks"
    use_cases:
      - sub_agent
      - compaction
      - sentinel
    supports_tools: true
    max_context_tokens: 200000
    cost_tier: low

  - id: "google/gemini-2.0-flash-001"
    tier: fast
    description: "Gemini 2.0 Flash — very fast, low cost, multimodal including audio input"
    use_cases:
      - sub_agent
      - compaction
      - sentinel
      - audio_transcription
    supports_tools: true
    max_context_tokens: 1048576
    cost_tier: low

  - id: "openai/gpt-4.1-mini"
    tier: cheap
    description: "GPT-4.1 Mini — budget option with decent tool calling"
    use_cases:
      - sub_agent
      - compaction
      - sentinel
    supports_tools: true
    max_context_tokens: 1047576
    cost_tier: low

  # Audio-capable models — can transcribe speech input and/or generate speech output.
  # These complement ElevenLabs TTS; audio_output models can be used as an alternative
  # when native audio responses are preferred (e.g. lower latency, conversational voice).

  - id: "google/gemini-3-flash-preview"
    tier: balanced
    description: "Gemini 3 Flash Preview — fast, large context, audio input, $0.50/$3 per M tokens"
    use_cases:
      - orchestrator
      - sub_agent
      - compaction
      - audio_transcription
    supports_tools: true
    max_context_tokens: 1048576
    cost_tier: low

  - id: "google/gemini-3-pro-preview"
    tier: primary
    description: "Gemini 3 Pro Preview — top-tier reasoning, audio input/output, $2/$12 per M tokens"
    use_cases:
      - orchestrator
      - sub_agent
      - audio_transcription
      - audio_output
    supports_tools: true
    max_context_tokens: 1048576
    cost_tier: high

  - id: "openai/gpt-audio"
    tier: primary
    description: "GPT Audio — native audio input and output, 128k context, $2.50/$10 per M tokens, $32 audio tokens; alternative to ElevenLabs TTS"
    use_cases:
      - sub_agent
      - audio_transcription
      - audio_output
    supports_tools: true
    max_context_tokens: 128000
    cost_tier: high

  - id: "openai/gpt-audio-mini"
    tier: balanced
    description: "GPT Audio Mini — native audio input/output, 128k context, $0.60/$2.40 per M tokens, $0.60 audio tokens; low-cost audio alternative"
    use_cases:
      - sub_agent
      - audio_transcription
      - audio_output
    supports_tools: true
    max_context_tokens: 128000
    cost_tier: medium

# ---------------------------------------------------------------------------
# Voice Configuration — ElevenLabs TTS settings
# ---------------------------------------------------------------------------
#
# voice_id uses env var interpolation for flexibility across environments.
# tts_model selects the ElevenLabs model (see API docs for options).
# optimize_streaming_latency: 0 (max quality) to 4 (min latency).
# voice_settings are optional overrides; ElevenLabs uses voice defaults if omitted.

voice:
  voice_id: "${ELEVENLABS_VOICE_ID}"
  tts_model: "eleven_flash_v2_5"
  optimize_streaming_latency: 3
  output_format: "mp3_44100_128"
  voice_settings:
    stability: 0.5
    similarity_boost: 0.75
    style: 0.0
    speed: 1.0
